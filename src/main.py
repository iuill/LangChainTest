# ref: https://qiita.com/hiroki_okuhata_int/items/7102bab7d96eb2574e7d

import os
import shutil

from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.document_loaders import PyPDFLoader

# è‡ªæ°‘å…šAIã®é€²åŒ–ã¨å®Ÿè£…ã«é–¢ã™ã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒ¼ãƒ  ãƒ›ãƒ¯ã‚¤ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ https://note.com/akihisa_shiozaki/n/n4c126c27fd3d
target_pdf = (
    "https://note.com/api/v2/attachments/download/0c61c5696cd01694c4693164b8f54dc0"
)
# ç’°å¢ƒçœ ä»¤å’Œ4å¹´ç‰ˆ ç’°å¢ƒãƒ»å¾ªç’°å‹ç¤¾ä¼šãƒ»ç”Ÿç‰©å¤šæ§˜æ€§ç™½æ›¸ï¼ˆPDFç‰ˆï¼‰ https://www.env.go.jp/policy/hakusyo/r04/pdf.html
# target_pdf = "https://www.env.go.jp/policy/hakusyo/r04/pdf/full.pdf"

print("ğŸ”– PDF Load: START")
loader = PyPDFLoader(target_pdf)

pages = loader.load_and_split()
# content = pages[0].page_content

# APIã‚­ãƒ¼ãŒå¿…è¦(DevContainerã«ã‚ˆã‚Š.envã‹ã‚‰å–å¾—ã•ã‚Œã‚‹)
print("ğŸ”– Initialize Model: START")
llm = ChatOpenAI(temperature=0, model_name="gpt-3.5-turbo")
# llm = ChatOpenAI(temperature=0, model_name="gpt-4")

# OpenAIæä¾›ã®embeddingã‚’ä½¿ç”¨
embeddings = OpenAIEmbeddings()

# ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã¯OSSã®Chromaã‚’ä½¿ç”¨
db_directory = "./chromadb/"
if os.path.exists(db_directory):
    shutil.rmtree(db_directory)

print("ğŸ”– Stored in ChromaDB: START")
vectordb = Chroma.from_documents(
    pages, embedding=embeddings, persist_directory=db_directory
)
vectordb.persist()  # æ°¸ç¶šåŒ–

print("ğŸ”– Query: START")
pdf_qa = ConversationalRetrievalChain.from_llm(
    llm, vectordb.as_retriever(), return_source_documents=True
)

queries = [
    "ã“ã®ãƒ›ãƒ¯ã‚¤ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã¯ä½•ã‚’ä¸»å¼µã—ã¦ã„ã¾ã™ã‹ï¼Ÿ300æ–‡å­—ç¨‹åº¦ã‚’ç›®å®‰ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚ Please in Japanese.",
    "ã“ã®ãƒ›ãƒ¯ã‚¤ãƒˆãƒšãƒ¼ãƒ‘ãƒ¼ã«ã‚ˆã‚Šæˆ‘ã€…ãŒè¡Œå‹•ã™ã¹ãã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ Please in Japanese.",
]
chat_history = []

for query in queries:
    result = pdf_qa({"question": query, "chat_history": chat_history})

    print(f"ğŸ’¡ Q: {query}")
    print(f"ğŸš© A: {result['answer']}")

    sources = result["source_documents"]
    print(f"ğŸš€ source: {len(sources)} ä»¶ ğŸš€")
    for s in sources:
        print(f" ğŸ page: {s.metadata['page']} / {s.page_content}")

    print("")
    print("â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸â„ï¸")
    print("")

    chat_history = [(query, result["answer"])]

pass
